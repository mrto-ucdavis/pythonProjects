# -*- coding: utf-8 -*-
"""Lab1_part2_python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VsOtiu1hmvMZ_xxEqYdLU0KkzASAdgt6

# Experimental 1 Thermocouples, Part 2
Developer: <b>Thomas To</b><sup>1-7 </sup> (Transfer Undergraduate, 2021) <br>
Created:   July 2020 <br>
In collaboration with Dr. Jiandi Wan<sup>1</sup>, Dr. Harishankar Manikantan<sup>1</sup> and Ashley Vater<sup>2</sup>
1. Department of Chemical Engineering, University of California, Davis
2. Genome Center, University of California, 
  Davis <br>
3. McNair Scholar, University of California, Davis
4. Avenue<sup>E</sup> Scholar, University of California, Davis
5. Student Outreach Ambassador, University of California, Davis
6. Undergraduate Research Ambassador, University of California, Davis
7. Laney Community College, Peralta District, Oakland

These templates are meant to help facilltate the big picture workflow of
the data-analysis and are designed to help getting you started. 
Ultimately, the ways in which you handle the data both in and out of the
laboratory will influence the effectiveness of these templates. <br>

<b> For more individualized support with coding or data handling, <i><u> don't
hesitate</u></i> to reach out to the (specific) tutors who have previously 
taken the course or otherwise, general (non-specific) tutors 
who can help suggest how to approach data handling in MATLAB or Python3. </b>

# Calculating the Theoretical Time Constant (Tau)

 Throughout ECH 145A and B you'll notice these theoretical calculations
  can *typically* done before delving into your experimental data and often,
  can be done first before the experiment! <br>

  I recommend speaking to the professors on how to get started with
  theoretical calculations if you're wanting to get started early but I'll
  try my best to set these up for you in the beginning of these templates.
  This will be particuarly important in ECH 145B when you start learning
  how to implement the finite difference method you learned in ECH 140
  analytically. Eventually, (next quarter) you're going to do it numerically
"""

import numpy as np
diameterData = []#[Your Experimentally Determined Meassurements] #mm
ravg = np.mean(diameterData) * 1E-3 / 2
rerr = 2*np.std(diameterData)
K = 7.34E-6 # Units: m^2 s-1 Can you find a reference to confirm this?
tau_theory = np.power(ravg,2)/ (K*np.pi/2)

"""The homemade thermocouple was made out of a Chromega and Alomega mixture.
 Does the theoretical calculation make sense with this rationale?
 Alternatively, we can do the following to better represent this theoretical
 model to the experimental if we condiser taking an average of the two 
 materials' properties. <br>

 This includes densities, thermal diffusivities, heat capacities, etc. 
 Weighted sums using individual components of the mixture can be done 
 to accomodate for certain phyiscal properties as an approximation.
``` 
ALTERNATIVE METHOD (K): Chromega and Alomega
 diameterData = []; %mm
 r = (mean(diameterData) * 1e-3)/2; % Units: m
 r_error = 2*std(diameterData);
 
 rho = ( + )/2;
 cond = ( + )/2;
 heat = ( + )/2;
 K = cond/(rho * heat);
 tau_theoretical = r^2 / (K*pi^2);
```
---
 Once you look up the values compare the weighed physical
 values to the given K value. What is the K value given? Does it assume
 pure Chromega or pure Alomega? Question the values given to you!
 <b>It's okay if your experimental values are way off from the theoretical!</b>
 It's more reason for you to ask questions and understand why and what
 factors caused such differences!

# Writing, Formatting and Exporting Table 1 
##Prepartion for Discussion 1: Effects on Precision and Accuracy

For context on how I handled my data, I have a folder in the same directory as this file called, "Data_Lab_1.2" and in this main folder, I have folders that contain the conditions, "Ambient", "Ambient to Cold", "Ambient to Hot" and so forth. Each of these condition folders has folders that represent my trials. <br>

***Current Directory > "Data_Lab_1.2" Folder > Condition Folders > Trial Folders > Data Sheets (csv or excel)***

Inorder for this template to work properly: in the folder called "Data_Lab_1.2" you should have three folders called "Ambient", "Ambient to Cold" and "Ambient to Hot" In each of these folders should have the .xlsx file with your data. <br>

If you have .csv see the comments.

***If you have differing number of trials, you're going to need to take the lowest number of trials inorder to properly create the scatter plot. Figure parameters require the x and y inputs to be the same dimension (N by 1)***
"""

# Change directory as needed

"""## Determining the file path inorder to access the data of each trial per condition
The following template will proceed to offer insight on how to prepare and approach calculating the values for Table 1 and Discussion 1. It is up to you how to approach the remaining conditions.
"""

import os
# import data files (csv or excel) and store in respective condition vars after path
ambientPath = 'Data_Lab_1.2/Ambient'
ambient2coldPath = 'Data_Lab_1.2/Ambient to Cold'
ambient2hotPath = 'Data_Lab_1.2/Ambient to Hot'

filelist = [] #stores trial values by condition dictated by path above

# Store in list and loop through paths
for root, dirs, files in os.walk(ambient2coldPath):
  for file in files:
    if(file.endswith(".csv")): #change to .csv
      filelist.append(os.path.join(root,file))

for name in filelist:
  print(name)

"""## Using the path to access the data contained, take average & standard deviation per trial"""

import pandas as pd
import numpy as np
# Seperating and containing respected variables vals as needed
# Find average & std temperature for each condition: cold, ambient and hot
storevar = []
storeavgT = []
storestdT = [] 
NUMTRIALS = 5
for i in range(NUMTRIALS): 
  storevar.append(pd.DataFrame(pd.read_csv(filelist[i], skiprows=6))) # store trial data for use in indexing
  #storevar.append(pd.DataFrame(pd.read_excel(filelist[i], skiprows=6))) # store trial data for use in indexing
  storeavgT.append(np.mean(storevar[i]['CH1 (째C)']))
  storestdT.append(2*np.std(storevar[i]['CH1 (째C)']))

"""# Write (export) table with trial number, average Temperature, standard deviation of mean Temperature, Collection Rate (Hz), Sample Rate (Hz)"""

datattable = {'average temp C':storeavgT,
             'std temp':storestdT,
             'Collection Rate (Hz)': [], # input based on corresponding trial value to index
             'Sample Rate (Hz)': []} # input based on corresponding trial value to index
tabledf = pd.DataFrame(datattable, columns=['average temp C','std temp','Collection Rate (Hz)','Sample Rate (Hz)'])

# I prefer exporting to excel because it's more user friendly imo and easier to work with
# Will export to same directory level unless specified 
tabledf.to_excel("lab1Part2dataTable.xlsx",index=False)

tabledf.to_csv(r'./lab1Part2dataTable',index = False, header = True)
# ./ current directory

"""# Figure 1
The provided code will start all of the trials per condition at the start of the jump and account for any misaligned sensor timing during the experiment. Do not manipulate the time correction variable. <br>
<br>
The code is designed to only start at the beginning of a temperature
change. The remaining time and data will be logged until data collection
has ceased. This is on purpose to allow you to have a better
understanding of "T_infinite" and to showcase differences in theoretical
tau and experimnetal tau as you see approprate in the generated figure.

From the lab manual, "The starting time of this transition along with a point
that is one time constant greater in time than the
starting time should be clearly marked on the figure."

# Determine greatest temperature change and start time
Lets take a moment to understand what we're trying to do here:
"The plot should depict data for the thermocouple undergoing
a large temperature change."<br>

To me, this reminded me of calculus and when we're taking deriviatives. Let me try to explain. What made sense to me in a more practical sense was visualizing a titration curve! As time progresses, in the beginning the "changes" are small but after some amount of time, the change is large and this is the region of the graph we're interested in.<br>
"""

import matplotlib.pyplot as plt
# Initiating storing lists
startTval = []
starttval = []
timecorrection = []
startloc = []

# Determining the greatest change in temperature for both hot and cold conditions
for i in range(NUMTRIALS):
  # finding max value
  diff = abs(np.diff(np.array(storevar[i]['CH1 (째C)'])))
  # finding index of max value and store
  startloc.append(diff.tolist().index(max(diff)))
  # using the location of max change, use corresponding index on sensor data to start graph (time, temperature)
  startTval.append(storevar[i]['CH1 (째C)'][startloc[i]:])
  starttval.append(storevar[i]['Time (s)'][startloc[i]:]) # analyze each graph and subtrate by this correcting value to align trials
  timecorrection.append(storevar[i]['Time (s)'][startloc[i]]) # no need for : since we're intersted in the corresponding start time to align graphs respectively of trials (& conditions)

# start(T/t)val[trials]
for i in range(NUMTRIALS):
  j = i+1 # Convienent naming convention for trials
  ambient2coldplot = plt.plot(starttval[i]-timecorrection[i], startTval[i], 'o', label='Trial #%i' %j)
  
plt.legend()
plt.xlabel('time, s')
plt.ylabel('Temperature $\circ$ C')
plt.show()

"""# Determining the Experimental Time Constant, $\tau$
Determine the Experimental Time Constant, See Appendix in Lab Manual <br>
`T( t = tau ) = Tinf + (Tinit - Tinf) / np.exp(1)`<br>
Tinf for boiling is approximately 100.0 C at approximately 1.0 atm<br>
Tinf for cold (ice) is approximately 0.0 C at approximately 1.0 atm<br>
Tinit is room temperature in this case<br>

*A time correction is needed to align start of jumps to t = 0 inorder to account for the varying times the thermocouple is used.*<br> 
<br>
Once you've determined the experimental tau for your
experiment, go back into the code above and annotate the figure as needed to clearly mark (on the figure) a point that is one time constant later than the starting time; which has been determined to be the start of the jump
"""

# Experimental Time Constant Calculation

"""#Calculating Mole Fraction of Sodium Acetate"""

# Import Salt Data

# Average Salt Temperature for each trial

# Average Salt Temperature across each trial
elevatedTemp = np.mean()
# Error to Two Standard Deviations
elevatedTemperror = 2*np.std()

# Clausius-Clapeyron equation
boilingPoint =

Kb = 0.510; # Units: C kg mol-1 found in literature
delT = elevatedTemp - boilingPoint;
i = 2;
molality = delT/(Kb*i);
molSalt = molality;
molWater = 1000/18.01528;
molfracSalt = molSalt/(molSalt + molWater)

# Error Propagation